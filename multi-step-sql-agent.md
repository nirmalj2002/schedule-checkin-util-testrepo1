# DEVIN.AI MASTER PROMPT  
pfBa-gyDjLBlQ0awL2g5a0Dd8bmTm2Kokq3CZByexmCqZdcX6GyGnld7m5vpK1t6XaMJc9trKET3BlbkFJnpqWOGYoZembkq7FU18_x0APHsGNZSz73p0WkFaHw5-MvFxX5PUdSRQ8WqFnc-bpeIYr-1OX
**NO REPOSITORY TO BE REFERRED**

### Project Title:
**Build a Schema-Agnostic Multi-Step for Natural Language to SQL/Hive Query Generation with YAML Schema Intelligence, Streamlit UI, and FastMCP API.**

---
## Project Summary
You are to build a multi-step SQL query generation AI agent that converts natural language requests into executable SQL and HiveQL queries.
The agent should support both relational (SQL) and Hive-style (Parquet) query formats, with a flexible architecture to switch between OpenAI and other LLM providers (like Anthropic, Gemini, or local models).

Use Python as the base language. Use Streamlit for the web-based UI, and FastMCP to expose the agent’s workflow as a modular MCP API service.

---
## Objective

Develop an **AI Agent System** that:
- Converts **natural language requests** into **optimized SQL or HiveQL** queries  
- Is **schema-agnostic** — no hardcoded DB schema  
- Accepts **external schema files** in **YAML or JSON** format for schema-awareness  
- Supports **multiple LLMs** (OpenAI default, switchable architecture)  
- Provides a **Streamlit UI** for human interaction  
- Exposes **FastMCP API endpoints** for automation and agentic integration  
- Is **fully testable**, **self-correcting**, and **modular** in design  



---
## System Overview — Multi-Agent Workflow

| Agent | Responsibility |
|--------|----------------|
| **Controller Agent** | Orchestrates flow across all sub-agents; manages state and coordination. |
| **Schema Loader** | Loads, Parse and validates YAML/JSON schema files, provides schema context to agents. |
| **Schema Linker Agent** | Maps natural language to relevant schema entities (tables, columns, metrics). |
| **Decomposer Agent** | Breaks down complex natural language into sub-tasks and logical steps. |
| **Sub-SQL Generator Agent** | Builds SQL/Hive query fragments (CTEs, filters, joins, etc.). |
| **Refiner Agent** | Validates, tests, and self-corrects the generated query using feedback loops. |
| **Executor Agent** | Executes final queries on DuckDB (SQL) or PySpark/DuckDB (Hive/Parquet). |
| **Visualizer Agent** | Displays query results in Streamlit (table/chart) with export capability. |

---
## Schema Configuration (Schema-Aware Intelligence)

The system is schema-agnostic but becomes schema-aware by loading a schema definition file.

### Example Schema File (`schemas/retail_sales.yaml`)

schema_name: risk_calc_stats
dialects:
  - sql
  - hiveql

tables:
  calc_stat_raw:
    description: Table used to store raw data for calculation statistics for risk calculation process that is used to calculate risk for various securities, runs in multiple phases, executed on distributed compute grid. The data generated by this process uses different risk models and actual data stored in various tables. calc_stat_raw table will store raw data for calculation metrics only like cpu usage, number of grid calls for given combination (region, eod date, phase, model, host name) for a given security.
    columns:
		region: VARCHAR/TEXT #Region for which will have calculation statistics - APAC, EMEA, NAM
		eodDate: INTEGER #End-of-day date (YYYYMMDD) e.g. 20250924, 20250923
		phase: VARCHAR/TEXT	#isk calculation phase e.g RUN_PH01, RUN_PH02, RUN_PH03 ....  RUN_PH10
		modelName: VARCHAR/TEXT	#Model name that used to generate risk data e.g. MODEL01, MODEL02, MODEL03.... MODEL20
		hostName: VARCHAR/TEXT	#Host on calculation grid that processes the security for given combination  e.g. XAHOST001, XAHOST002.... XAHOST400
		securityId: INTEGER	#Security identifier e.g 100001 to 105000 for APAC, 200001 to 205000 for EMEA, 300001 to 305000 for NAM
		securityType: VARCHAR/TEXT #Type of security e.g. SEC_TYPE01, SEC_TYPE02 ....SEC_TYPE15
		cpuUsageInSeconds: INTEGER #Simulated CPU usage in seconds, can vary from 300 to 9500 seconds
		calcGridCalls: INTEGER #Number of calls dispatched to grid, can vary from 1 to 300
    relationships:
      - region -> calc_stat_daily_summary.region
      - eodDate -> calc_stat_daily_summary.eodDate

  calc_stat_daily_summary:
    description: Description: View used to aggregated daily calculation statistics by region for a given day e.g total cpu usage, total calc grid calls, total security processed etc.
    columns:
		region: VARCHAR/TEXT #Region for which will have calculation statistics - APAC, EMEA, NAM
		eodDate: INTEGER #End-of-day date (YYYYMMDD) e.g. 20250924, 20250923
		phaseCount: INTEGER #Count of distinct phases for given region and eod date
		modelCount: INTEGER #Count of distinct model names for given region and eod date
		hostCount: INTEGER #Count of distinct host names for given region and eod date 
		securityCount: INTEGER #Count of distinct security id for given region and eod date
		securityTypeCount: INTEGER #Count of distinct security types for given region and eod date
		totalCpuUsageInHours: INTEGER #Total of CPU usage in hours for given region and eod date. Convert total seconds to total hours
		totalCalcGridCalls: INTEGER #Total of Calc grid calcs for given region and eod date
	  
semantic_hints:
  metrics:
    securityCount: "SUM(securitiId)"
    totalCpuUsageInHours: "SUM(cpuUsageInSeconds)/3600"
    totalCalcGridCalls: "SUM(calcGridCalls)"
  time_fields:
    - eodDate

---
**Folder Structire**

project/
├── agents/
│   ├── controller_agent.py
│   ├── schema_linker_agent.py
│   ├── decomposer_agent.py
│   ├── sub_sql_generator_agent.py
│   ├── refiner_agent.py
│   ├── executor_agent.py
│   └── visualizer_agent.py
├── core/
│   ├── schema_loader.py
│   ├── llm_provider.py
│   └── config.py
├── api/
│   └── fastmcp_server.py
├── ui/
│   └── streamlit_app.py
├── schemas/
│   └── retail_sales.yaml
├── tests/
│   ├── test_schema_loader.py
│   └── test_end_to_end.py
└── README.md

---
**Core Components and Implementation Guide**
1. core/schema_loader.py

import yaml, json
from pathlib import Path

class SchemaLoader:
    @staticmethod
    def load(schema_path: str):
        ext = Path(schema_path).suffix.lower()
        with open(schema_path, 'r') as f:
            data = yaml.safe_load(f) if ext in ['.yaml', '.yml'] else json.load(f)
        return data

    @staticmethod
    def validate(schema: dict):
        required_keys = ['tables', 'dialects']
        for key in required_keys:
            if key not in schema:
                raise ValueError(f"Schema missing required key: {key}")
        return True

---
2. core/llm_provider.py

from abc import ABC, abstractmethod
import openai

class LLMProvider(ABC):
    @abstractmethod
    def generate(self, prompt: str, context: dict = None) -> str:
        pass

class OpenAIProvider(LLMProvider):
    def __init__(self, model="gpt-4o-mini"):
        self.model = model

    def generate(self, prompt: str, context: dict = None) -> str:
        response = openai.ChatCompletion.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return response.choices[0].message["content"]

class LocalMockProvider(LLMProvider):
    def generate(self, prompt: str, context: dict = None) -> str:
        return f"MOCK_RESPONSE: {prompt[:100]}"

---
3. agents/schema_linker_agent.py

from difflib import get_close_matches

class SchemaLinkerAgent:
    def __init__(self, schema: dict):
        self.schema = schema

    def find_relevant_entities(self, user_query: str):
        all_columns = []
        for table, data in self.schema.get('tables', {}).items():
            for col in data.get('columns', {}):
                all_columns.append(f"{table}.{col}")

        matches = get_close_matches(user_query.lower(), all_columns, n=5, cutoff=0.3)
        return {"matches": matches}

---
4. agents/decomposer_agent.py

class DecomposerAgent:
    def decompose(self, user_query: str):
        # Basic step decomposition logic
        return {
            "intent": user_query,
            "steps": [
                "Identify target metric and filters",
                "Select relevant tables",
                "Determine group-by columns",
                "Assemble SQL structure"
            ]
        }


---
5. agents/sub_sql_generator_agent.py

class SubSQLGeneratorAgent:
    def generate(self, decomposed, schema_context):
        return f"-- SQL generated for: {decomposed['intent']}\nSELECT * FROM sales LIMIT 5;"

---
6. agents/refiner_agent.py
class RefinerAgent:
    def refine(self, sql_query: str):
        # Placeholder for SQL syntax validation & correction logic
        return sql_query

---
7. agents/executor_agent.py

import duckdb, pandas as pd

class ExecutorAgent:
    def execute(self, query: str):
        try:
            con = duckdb.connect()
            df = con.execute(query).fetchdf()
            return df
        except Exception as e:
            return {"error": str(e)}

---
8. API Layer (api/fastmcp_server.py)
from fastmcp import FastMCP
from core.schema_loader import SchemaLoader
from agents.sub_sql_generator_agent import SubSQLGeneratorAgent

app = FastMCP()

@app.post("/generate_query")
def generate_query(nl_query: str, schema_path: str):
    schema = SchemaLoader.load(schema_path)
    generator = SubSQLGeneratorAgent()
    return generator.generate({"intent": nl_query}, schema)

if __name__ == "__main__":
    app.run()

---
9. Streamlit UI (ui/streamlit_app.py)
import streamlit as st
from core.schema_loader import SchemaLoader
from agents.schema_linker_agent import SchemaLinkerAgent
from agents.decomposer_agent import DecomposerAgent
from agents.sub_sql_generator_agent import SubSQLGeneratorAgent
from agents.refiner_agent import RefinerAgent
from agents.executor_agent import ExecutorAgent
import pandas as pd

st.title("🧠 Schema-Agnostic SQL/Hive Query Generator")

uploaded_schema = st.file_uploader("Upload schema (YAML/JSON)")
user_query = st.text_input("Enter natural language query")

if uploaded_schema and user_query:
    schema_data = SchemaLoader.load(uploaded_schema)
    linker = SchemaLinkerAgent(schema_data)
    decomposer = DecomposerAgent()
    generator = SubSQLGeneratorAgent()
    refiner = RefinerAgent()
    executor = ExecutorAgent()

    linked = linker.find_relevant_entities(user_query)
    decomposed = decomposer.decompose(user_query)
    sql_query = generator.generate(decomposed, schema_data)
    refined_sql = refiner.refine(sql_query)
    st.code(refined_sql, language="sql")

    if st.button("Execute Query"):
        result = executor.execute(refined_sql)
        st.dataframe(result if not isinstance(result, dict) else pd.DataFrame([result]))

----
10. Testing (tests/test_schema_loader.py)
from core.schema_loader import SchemaLoader
import pytest

def test_load_and_validate_schema():
    schema = SchemaLoader.load("schemas/retail_sales.yaml")
    assert "tables" in schema
    assert SchemaLoader.validate(schema) is True

---
**Testability Requirements
	1. Unit and integration tests using pytest.
	2. Mock database/schema for offline testing.
	3. Each agent must have at least one test verifying:
	4. Input/output correctness
	5. Failure handling and recovery
	6. Implement a run_all_tests.py script that runs test suites and outputs a summary.

---
**Example Query Flow**
	User Input:
		“Show top 5 regions by revenue in the last 60 days.”

	Agent Steps:
		1. Schema Loader: loads retail_sales.yaml
		2. Schema Linker: matches tables sales, customers
		3. Decomposer: splits query intent into logical subtasks
		4. Generator: builds base SQL or HiveQL
		5. Refiner: validates and corrects syntax or column names
		6. Executor: executes query on DuckDB or Hive
		7. Visualizer: renders chart/table in Streamlit
---
**Acceptance Criteria**
	1. Schema-agnostic core
	2. Schema-aware via YAML/JSON config
	3. SQL + Hive dialect support
	4. LLM provider interface (OpenAI + switchable)
	5. Streamlit UI for natural language input
	6. FastMCP API endpoints for automation
	7. Pytest coverage for all agents
	8. Modular, self-contained codebase

---
**To make the system fully testable end-to-end, add:**
	1. run_all_tests.py to trigger all pytest suites
	2. A small mock SQLite/Parquet dataset under /data/ for offline query testing

---
**Deliverable:**
	A modular, schema-agnostic, multi-step AI query generation system with UI + API integration, ready for deployment or extension into an AI Data Analyst Assistant.
